# 大宝大话大数据（一）大数据的骨架

学习和使用大数据工具已经一年多了，经历了看书自学，实习实践，理解原理这几个重要阶段的铺垫后，自我感觉算是对大数据开发初步入门了。也想借此机会对所学内容做一个总结和归纳。方便自己查阅的同时，也希望帮助到需要的同学。全部内容会更新在我的github上，手搜https://github.com/tygxy。

本系列的写作安排主要围绕自己的知识体系展开，主要涉及三个方面的内容：大数据整体概述和学习方法、大数据常见组件的使用、组件原理串讲。这三个方面分别对应不同读者的三类需求，即
	- Part 1 大数据究竟是什么，怎么学？
	- Part 2 大数据组件在开发中怎么用？
	- Part 3 这些组件的原理是什么？

以上三个方面分别对应大数据小白，入门，找工作三个不同深度的需求，如果只是想了解概念，只读Part 1即可；如果是在开发中需要具体使用，建议阅读到Part 2；如果需要参与实习秋招，就必须对常见组件的原理有一定的理解，可以参阅Part 3。

恕本人愚钝，自己的技术水平还很初级，使用和理解的程度还远远不够，甚至有错。只期望抛砖引玉，非常欢迎大佬批评指正，相互探讨，共同提高。

闲话少叙，本期这一节主要是介绍大数据的骨架，希望通过这一节，读者可以对大数据有一个框架般的认识。

![](/resource/talkingbigdata1.jpg?raw=true)

大数据，我的理解是用分布式手段去解决海量数据在收集、存储、流转、计算、消费中的问题。如图所示，借用通信原理中最常见的信源-信道-信宿的结构概念。我尝试画出了数据从产生到消费的过程。几乎所有组件都是尝试解决上述问题中的一部分，并最终整合起来，构成大数据的整体解决方案。

![](/resource/talkingbigdata2.jpg?raw=true)

如图所示，这是我现阶段理解的大数据框架，主要基于Hadoop2.0+。

整体看分为五个层次，从下到上分别是采集层、存储层、调度层、计算层、交互层。

先说存储层，海量数据在单机内已经无法存储，解决方案是依靠分布式。将数据存储在N台机器构成的集群之上，并依赖一定的HA(High Available)机制保证数据的可靠性和可拓展性。开源的方案就是Hadoop中的HDFS组件，作为分布式文件系统，HDFS是海量文件的存储池，也是整个大数据生态体系的基石之一。

在存储层之上，就是调度层。Hadoop2.0提供的解决方案是Yarn。我们可以假想一个场景，在大数据平台之上，肯定会有很多作业任务需要运行，那么如何将集群的资源分配，如何调度这些Task任务完成，这就依赖Yarn做统一安排。Yarn作为通用资源调度器，可以管理MapReduce、Spark、Storm等诸多作业。

再往上就是大数据的另外一个核心，计算层。针对批处理、流计算两类不同的业务场景，分别衍生出MapReduce、Spark、Storm、Spark Steaming、Flink等计算框架。不同的公司有不同的技术选型，这些计算框架，在各自的领域发挥着强大效能。作为大数据开发工程师，需要熟悉几个框架的编程。

最上面是交互层，它们是为了方便开发，提供的一些便捷组件。比如Hive可以做数据仓库、Spark SQL可以操作一些结构化数据、Impala可以做实时交互式查询等。本质来说，上述工具可以理解成“接口”，最终都会转换成计算层的执行引擎去具体执行。交互层的工具方便了我们的开发，也是我们工作中必不可少的利器。

翻回头我们在谈一下采集层，采集层是用来收集和转发数据。Flume是日志收集工具，Kafka是经典的消费队列，Sqoop是ETL工具等。这些工具同样是为了解决大数据处理中的一些具体场景诞生的应用，对整个生态圈起到了支撑的拓展的作用。

在图的最左侧是Zookeeper，为整个集群的部分组件，比如HBase，Kafka提供协调服务。它是集群的管理者，监视着集群中各个节点的状态并根据节点的反馈做合理的操作。

综上，我们看到采集层解决的是大数据的收集和流通，存储层解决的是大数据的存储，计算层和交互层解决的是大数据的计算和消费问题。

通过刚才的阐述，我希望小白同学理解几个方面的问题：
	- 大数据解决了什么问题
	- 这一套流程的总体框架是什么，分为哪几个层级，每个层级具体干什么
	- 几个常用的组件分别所属哪些层级

看完这篇文章，如果对上面三个问题有了答案，就再好不过了。

刚才的三个问题也是对我这篇文章的一个简单梳理，大数据涉及的内容比较多，乍一看挺复杂的，但是本质上讲不难。下一篇文章，我会结合自己有限的学习经历，讲讲应该如何学习大数据。

谢谢大家！
