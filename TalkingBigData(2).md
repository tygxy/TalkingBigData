# 大宝大话大数据（二）大数据的学习路径和方法

本文将对自己学习大数据的路径和方法做一个回顾，有意入门大数据开发的同学可以参阅我的学习过程，结合自己的实际情况，做一些优化和调整。以下内容都是我的一家之言，仅供参考。

首先说下学习方法的问题。

我刚开始学大数据的时候，还没有老师和学长给我理清大数据的整体架构。我还真是盲人摸象，今天学学MapReduce，明天看看Spark。当时上刘军老师《海量数据处理》这门课的时候，老师很好，很认真讲了Hadoop的原理，结构什么的。但是说实话，作用很小。在没有整体框架搭起来，没有一些实际的操作经验作为铺垫之前，就讲这些原理和细节，根本就听不懂在干嘛。

计算机技术又是一个讲究实效的学科，空洞的原理很快就会打消学习的兴趣，而且在公司是以结果为导向，看你能不能搞定。所以我自己总结的学习计算机某一项技术的三把斧：
	- 快速上手，现学现用
	- 遇到问题，网上百度
	- 剖析原理，理解提高

比如我要学习Redis，第一步我就先从网上找资料，了解它是个什么东西，解决了一个什么问题，在整个计算机开发中属于什么定位；第二步就是在实际案例中，具体怎么使用。比如自己电脑安装一个Redis，用Java写一个读写Redis的小demo，中间遇到任何问题，先去网上找资源找答案，如果解决不了再去求助他人；在使用一段时间后，对Redis玩的比较溜了，就可以看一些高水平的博客，书籍，对Redis的原理，设计思路有一些了解，这样也会帮助开发，提升自己的知识储备。

这个套路是比较适合我的学习方式，我在自己学习Spark的过程中，基本就是这样。先快速学习了一些概念和demo，然后在美团做了一些的开发，最后翻过头来再学习Spark的原理，就理解的比较快。

学习方法本事就是见仁见智，这里仅供参考。

其次做为一个程序员，无论做前端、后台、客户端还是算法数据，有一些基础知识是必备的：
	- 掌握编程语言，Java|C++ && Python|Shell
	- 熟悉Linux常用命令
	- 熟练SQL

我认为上述三项技能在日常工作中经常用到，有必要对其有基本的了解和使用经验。注意，这里只要求做到有使用经验，可以参阅API、文档去处理特定任务即可。有不会的百度就可以了。千万别花太大精力研究的太深，目前这个阶段用不着。

最后就是重头戏了，怎么开始学习大数据。

![](/resource/talkingbigdata2.jpg?raw=true)

还是把这张图贴出来，对这些组件还不清楚的读者可以翻阅我之前的文章。

第一步首先学习大数据的基石——Hadoop2.0+，尤其要理解HDFS、Yarn、MR在整个体系中的作用。基本技能是HDFS那点命令，重点理解HDFS的设计结构，HA机制，读写过程；MapReduce的原理，Hadoop2.0的改进点。在自己电脑上部署一个伪分布式的集群，尝试HDFS的操作。

第二步学习Spark，学习使用scala/python写一些批处理的程序。基本技能是Spark RDD的编程，重点理解常见算子、Spark任务提交流程、Shuffle、分区、数据倾斜怎么办。同样在自己电脑上安装spark，使用local、yarn两种模式提交jar包

第三步学习Hive，使用Hive shell做常见的表操作、使用Hive SQL做一些批处理。理解Hive是如何从SQL语句翻译到MR作业的。在此过程中，学习数据仓库的概念。同样自己电脑安装，学习使用。

第四步继续学习Spark进阶，学习Spark的其他组件、比如Spark SQL、MLlib等。还可以根据项目需求，学习Sqoop、Hbase等组件。这个时候可以做一些项目，比如结合Hive、HDFS、jdbc、Sqoop、Hbase做一些离线处理的项目；比如使用MLlib做一些简单的机器学习。通过上述四步，应该对基本的大数据批处理上手了。

第五步学习Flume，kafka。学习Flume的结构和配置，学习kafka的基本原理和结构，能使用java/scala写kafka的生成者和消费者demo。理解zookeeper在集群中的作用，和它的工作原理。电脑上安装软件，学习使用。

第六步学习Spark Steaming/Storm。使用scala/java写流计算的demo，理解有状态算子、checkpoint、window等概念。结合flume、kafka、做一个简单的日志处理平台。完成这一步对基本的大数据流计算上手。

第七部，实际上到这里，就对整个大数据有了基本的理解了。对各种组件有较多使用经验、对一些经典的组件原理也有所理解。这个时候可以根据需要，查缺补漏。继续学习新的大数据组件，或者补充学习一些AI的算法。

最后推荐一些看过的书做参考吧：
	- 《Sparkk快速大数据分析》，初学spark可以看
	- 《Spark大数据分析实战》，spark实战系列，可以跟着学一些项目
	- 《Spark技术内幕-深入解析Spark内核架构设计》，在对Spark有了实践后，读一读理解spark的优秀设计
	- http://spark.apache.org/ 官网，demo来源
	- 《spark性能优化指南-初级篇|高级篇》 spark性能优化必看
	- 《Hadoop实战》，很厚的一本书
	- 《kafka入门与实践》，初学kafka可以看
	- 《mysql必知必会》,SQL入门书籍
	- 《疯狂的Java》，Java EE入门

还有一些博客
	- http://lxw1234.com/ lxw的大数据田地
	- https://www.iteblog.com/ 过往记忆
	- http://dblab.xmu.edu.cn/ 厦门大学数据库实验室
	- http://www.java1234.com/a/javabook/ 可以下载一些电子书

大数据知识点比较杂，需要有耐心和兴趣。可以从事数仓、ETL、数据分析、批处理开发、流计算开发、平台开发等相关工作。在目前主流的互联网公司、银行等，大数据已经非常成熟了，已经是生产运营不可缺少的一部分。对于最热的算法同学来说，熟练掌握大数据工具也是必备技能。所以欢迎同学们根据需要，尝试了解和学习大数据吧。

谢谢大家！





